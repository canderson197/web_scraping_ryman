{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4159c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f491d7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://ryman.com/events/'\n",
    "\n",
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c23841",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd606e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7863b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f6f4f",
   "metadata": {},
   "source": [
    "1. Start by using either the inspector or by viewing the page source. Can you identify a tag that might be helpful for finding the names of all performers? For now, just worry about the headliner and don't worry about the opener. (Eg. For Vince Gill, featuring Wendy Moten, we only care about Vince Gill.) Make use of this to create a list containing just the names of each inductee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ceb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman_soup = BS(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1d32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we just look for a tags where class=tribe-event-url, which if you look, all of the a tags with band titles have this class\n",
    "a_tags_2 = ryman_soup.findAll('a', attrs = {'class':'tribe-event-url'})\n",
    "a_tags_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388a3d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to extract the title of just one before putting in a list comp\n",
    "a_tag_1 = a_tags_2[0]\n",
    "a_tag_1.get('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_2 = [x.get('title') for x in a_tags_2]\n",
    "titles_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7865006",
   "metadata": {},
   "source": [
    "2. Next, try and find a tag that could be used to find the date and time for each show. Extract these into two lists, one containing the date and the other containing the time. (Eg. THURSDAY, AUGUST 4, 2022 AT 8:00 PM CDT should be split into August 4, 2022 and 8:00 PM CDT.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735d72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ryman_soup.findAll('time')\n",
    "#type(time)\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb2adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract text only from ResultSet\n",
    "time_text = [x.text for x in time]\n",
    "time_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f7c567",
   "metadata": {},
   "source": [
    "extract the SHOWTIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try slicing on one before loop, it works\n",
    "time_1 = time_text[0]\n",
    "time_1[-11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17177495",
   "metadata": {},
   "outputs": [],
   "source": [
    "showtime_texts = [x[-11:] for x in time_text]\n",
    "showtime_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure out how to slice one date\n",
    "date_1 = time_text[0]\n",
    "print(date_1)\n",
    "date_1[:date_1.index(' at')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93350aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_texts = [x[:x.index(' at')] for x in time_text]\n",
    "date_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df88d52",
   "metadata": {},
   "source": [
    "3. Take the two lists you created on parts 1 and 2 and convert it into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec9808",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryman_df_pg1 = pd.DataFrame({'band':titles_2, 'showtime':showtime_texts, 'date':date_texts})\n",
    "ryman_df_pg1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a3d6e",
   "metadata": {},
   "source": [
    "4. Now, you need to take what you created for the first page and apply it across multiple rest of the pages so that you can scrape all inductees. Notice how the url changes when you click the \"More Events\" button at the top of the page. Check that the code that you wrote for the first page still works for page 2. Once you have verified that your code will still work, write a for loop that will cycle through the first five pages of events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc41df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://ryman.com/events/list/?tribe_event_display=list&tribe_paged=2'\n",
    "req = requests.get(URL)\n",
    "#req.status_code\n",
    "ryman_soup_2 = BS(req.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbdb6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_pg2 = ryman_soup_2.findAll('a', attrs = {'class':'tribe-event-url'})\n",
    "titles_pg2 = [x.get('title') for x in a_pg2]\n",
    "titles_pg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL2 = 'https://ryman.com/events/list/?tribe_event_display=list&tribe_paged='\n",
    "#so you can see what's happening in the loop: it iterates through the 5 web pages we want\n",
    "for page in range (1,6):\n",
    "    print(URL2 + str(page))\n",
    "    print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81b34f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL2 = 'https://ryman.com/events/list/?tribe_event_display=list&tribe_paged='\n",
    "\n",
    "artist_list = []\n",
    "\n",
    "for page in range (1,6): \n",
    "    req = requests.get(URL2 + str(page))\n",
    "    soup = BS(req.text)\n",
    "    a_tags = soup.findAll('a', attrs = {'class':'tribe-event-url'})\n",
    "    titles = [x.get('title') for x in a_tags]\n",
    "    artist_list.extend(titles)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1041156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1332ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL2 = 'https://ryman.com/events/list/?tribe_event_display=list&tribe_paged='\n",
    "\n",
    "showtime_list = []\n",
    "\n",
    "for page in range (1,6):\n",
    "    req = requests.get(URL2 + str(page))\n",
    "    soup = BS(req.text)\n",
    "    time = soup.findAll('time')\n",
    "    time_text = [x.text for x in time]\n",
    "    showtimes = [x[-11:] for x in time_text]\n",
    "    showtime_list.extend(showtimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25820ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "showtime_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afffb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL2 = 'https://ryman.com/events/list/?tribe_event_display=list&tribe_paged='\n",
    "\n",
    "date_list = []\n",
    "\n",
    "for page in range (1,6):\n",
    "    req = requests.get(URL2 + str(page))\n",
    "    soup = BS(req.text)\n",
    "    time = soup.findAll('time')\n",
    "    time_text = [x.text for x in time]\n",
    "    dates = [x[:x.index(' at')] for x in time_text]\n",
    "    date_list.extend(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e08698",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dfdab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#end result is a dataframe of the band, showtime and date for events from the first 5 web pages\n",
    "ryman_df = pd.DataFrame({'band':artist_list, 'showtime':showtime_list, 'date':date_list})\n",
    "ryman_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
